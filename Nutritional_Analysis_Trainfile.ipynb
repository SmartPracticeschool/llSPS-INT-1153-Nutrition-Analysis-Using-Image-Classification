{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4589,
     "status": "ok",
     "timestamp": 1589898674869,
     "user": {
      "displayName": "Nagamallika Dusanapudi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-YGGiiN84yJbLvw3DPDptnFkIN48kgLjJxuWo=s64",
      "userId": "01479854062051391847"
     },
     "user_tz": -330
    },
    "id": "KLwxs2VRU8Zi",
    "outputId": "fa4b7dc8-401f-4128-917d-87a96a9c24ef",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ebxt5LQYU8aj"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9031,
     "status": "ok",
     "timestamp": 1589898696301,
     "user": {
      "displayName": "Nagamallika Dusanapudi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-YGGiiN84yJbLvw3DPDptnFkIN48kgLjJxuWo=s64",
      "userId": "01479854062051391847"
     },
     "user_tz": -330
    },
    "id": "42r4MHzaU8ao",
    "outputId": "e1ae458c-fdbb-404e-b46a-1c1d1b178510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 254 images belonging to 4 classes.\n",
      "Found 104 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory('/content/drive/My Drive/fruits/train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                     class_mode = 'binary')\n",
    "x_test = test_datagen.flow_from_directory('/content/drive/My Drive/fruits/test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VI7kmgdHU8Zv"
   },
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4ecQRyLU8Z4"
   },
   "outputs": [],
   "source": [
    "# Add Convolution Layer\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rY9SUMSXU8Z-"
   },
   "outputs": [],
   "source": [
    "#Add Pooling Layer\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "30YEoCbsU8aF"
   },
   "outputs": [],
   "source": [
    "#Add Flattening Layer\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8456,
     "status": "ok",
     "timestamp": 1589898762395,
     "user": {
      "displayName": "Nagamallika Dusanapudi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-YGGiiN84yJbLvw3DPDptnFkIN48kgLjJxuWo=s64",
      "userId": "01479854062051391847"
     },
     "user_tz": -330
    },
    "id": "cayNu5lYU8aL",
    "outputId": "2ed91e84-51c7-4bd9-8e6b-768b9b1db938"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=20, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Add Hidden Layer\n",
    "model.add(Dense(init=\"uniform\",activation=\"relu\",output_dim=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6491,
     "status": "ok",
     "timestamp": 1589898773003,
     "user": {
      "displayName": "Nagamallika Dusanapudi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-YGGiiN84yJbLvw3DPDptnFkIN48kgLjJxuWo=s64",
      "userId": "01479854062051391847"
     },
     "user_tz": -330
    },
    "id": "BqwZlopiU8aX",
    "outputId": "518618b1-8bb0-4c50-8cec-0245c83b21c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=4, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Add Output layer\n",
    "from keras.layers import Dropout\n",
    "model.add(Dense(init=\"uniform\",activation=\"softmax\",output_dim=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rrjcpuBRU8ad"
   },
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5350,
     "status": "ok",
     "timestamp": 1589898775464,
     "user": {
      "displayName": "Nagamallika Dusanapudi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-YGGiiN84yJbLvw3DPDptnFkIN48kgLjJxuWo=s64",
      "userId": "01479854062051391847"
     },
     "user_tz": -330
    },
    "id": "QnCadi9fU8at",
    "outputId": "3d73fac4-f30a-4b22-9ea7-d54f514aa036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'guava': 0, 'jack': 1, 'papaya': 2, 'tamarind': 3}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1530528,
     "status": "ok",
     "timestamp": 1589900744616,
     "user": {
      "displayName": "Nagamallika Dusanapudi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-YGGiiN84yJbLvw3DPDptnFkIN48kgLjJxuWo=s64",
      "userId": "01479854062051391847"
     },
     "user_tz": -330
    },
    "id": "3kMlZuYiU8a0",
    "outputId": "f0ba3cda-d9a2-4b68-f2ee-df37b29c4475"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  3/250 [..............................] - ETA: 1:01:01 - loss: 1.3695 - accuracy: 0.3125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 294s 1s/step - loss: 0.4347 - accuracy: 0.8298 - val_loss: 0.2115 - val_accuracy: 0.8750\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 185s 739ms/step - loss: 0.1188 - accuracy: 0.9620 - val_loss: 0.1226 - val_accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 184s 735ms/step - loss: 0.0455 - accuracy: 0.9913 - val_loss: 0.3012 - val_accuracy: 0.8744\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 186s 744ms/step - loss: 0.0229 - accuracy: 0.9960 - val_loss: 0.0607 - val_accuracy: 0.9130\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 183s 730ms/step - loss: 0.0138 - accuracy: 0.9979 - val_loss: 0.6099 - val_accuracy: 0.8847\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 183s 733ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 1.1220 - val_accuracy: 0.9032\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 183s 732ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 0.1687 - val_accuracy: 0.8866\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 186s 743ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.1179 - val_accuracy: 0.8554\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 182s 730ms/step - loss: 0.0084 - accuracy: 0.9984 - val_loss: 1.2770 - val_accuracy: 0.9046\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 184s 734ms/step - loss: 9.5059e-04 - accuracy: 1.0000 - val_loss: 0.7831 - val_accuracy: 0.9026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f1173019240>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,\n",
    "                         steps_per_epoch =250,\n",
    "                         epochs =10,\n",
    "                         validation_data = x_test,\n",
    "                         validation_steps = 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWMEmxl9U8a5"
   },
   "outputs": [],
   "source": [
    "model.save(\"Nutritional_Analyzer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XgPmfL0fg-H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "nutritional_analysis_using_imageclassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
